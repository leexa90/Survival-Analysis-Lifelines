{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-9FxtlvHGTTw"
   },
   "source": [
    "# Survival Analysis :  Quick Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "id": "51NENvUvGTT4",
    "outputId": "d997fa39-28c6-4cf8-bf4a-ad4d175aa3e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "W: chmod 0700 of directory /var/lib/apt/lists/partial failed - SetupAPTPartialDirectory (1: Operation not permitted)\n",
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-227c647c202c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'apt-get update -qq 2>&1 > /dev/null'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'apt-get -y install -qq google-drive-ocamlfuse fuse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#install import stuff, you need to login and give google permissions twice\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
    "!pip install pandas==0.22\n",
    "!pip install lifelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "EuoIadJ0GTUH",
    "outputId": "25d894d4-639f-473c-8c44-76e63009e660"
   },
   "outputs": [],
   "source": [
    "#mount google drive\n",
    "%cd\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "OstZc6gqGTUQ",
    "outputId": "646d9256-d178-4fa0-cee5-6aaacef0078a"
   },
   "outputs": [],
   "source": [
    "#navigating your google drive and saving files inside.\n",
    "%cd\n",
    "%ls\n",
    "%cd drive/\n",
    "%mkdir github_fromXA\n",
    "%cd github_fromXA\n",
    "%rm -r Survival-Analysis-Lifelines\n",
    "!git clone https://github.com/leexa90/Survival-Analysis-Lifelines.git\n",
    "#download model parameters\n",
    "%ls -lh */\n",
    "%ls -lh\n",
    "%cd Survival-Analysis-Lifelines\n",
    "%ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BOwPmnlMGTUc",
    "outputId": "d4010ea1-9956-47f7-8e3d-af29aadf4387"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "pd.set_option('display.max_columns',60)\n",
    "pd.set_option('display.max_rows', 60)\n",
    "%pylab inline\n",
    "figsize(12,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ux6YZATOGTVD"
   },
   "source": [
    "### We will be using Telco Customer Churn data from IBM Watson Analytics\n",
    "https://www.ibm.com/communities/analytics/watson-analytics-blog/Telco-Customer-Churn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ip93GM5ZGTVI"
   },
   "outputs": [],
   "source": [
    "##  create a dataframe\n",
    "df = pd.read_excel(\"./WA_Fn-UseC_-Telco-Customer-Churn.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data description\n",
    "\n",
    "Customers who left within the last month – the column is called Churn\n",
    "\n",
    "Services that each customer has signed up for – phone, multiple lines, internet, \n",
    "online security, online backup, device protection, tech support, and streaming TV and movies\n",
    "\n",
    "Customer account information – how long they’ve been a customer, contract, payment method, \n",
    "paperless billing, monthly charges, and total charges\n",
    "\n",
    "Demographic info about customers – gender, age range, and if they have partners and dependents\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "colab_type": "code",
    "id": "PTf3iUZRGTVS",
    "outputId": "fb7c2e10-5fbf-41e3-be4e-402e8fc5dc37"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4d90f44b0ad9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Have a first look at the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "## Have a first look at the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all columns\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view churn column , row 2 - 17 #python index starts from 0\n",
    "df['Churn'].iloc[1:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of churn customers\n",
    "np.mean(df['Churn']=='Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique entries of tech support\n",
    "pd.unique(df['TechSupport'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access churn column from those who are on Tech support\n",
    "df[df['TechSupport']=='Yes']['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNBze7xbGTVt"
   },
   "outputs": [],
   "source": [
    "## Convert TotalCharges to numeric\n",
    "df['TotalCharges']=pd.to_numeric(df['TotalCharges'],errors='coerce')\n",
    "\n",
    "## Replace yes and No in the Churn column to 1 and 0. 1 for the event and 0 for the censured data.\n",
    "df['Churn']=(df['Churn']=='Yes')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in pd.unique(df['Contract']):\n",
    "    print ('type of contract:',i)\n",
    "    plt.hist(df[df['Contract']==i]['Churn'],density=True,bins=(0,1,2))\n",
    "    plt.xticks([0.5,1.5],labels=[0,1])\n",
    "    plt.xlabel('churn ==1, no churn ==0')\n",
    "    plt.ylabel('normazlied prob density')\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking column for missing entries\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#customers with missing values, fill in with median\n",
    "df[df['TotalCharges'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TKBF9Q4_GTV6"
   },
   "outputs": [],
   "source": [
    "## Impute the null value with the median value\n",
    "df.TotalCharges.fillna(value=df['TotalCharges'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wBnxqBmfGTWB"
   },
   "outputs": [],
   "source": [
    "## Create a list of Categorical Columns\n",
    "cat_cols= [i  for i in df.columns if df[i].dtype==object]\n",
    "cat_cols.remove('customerID')  ## customerID has been removed because it is unique for all the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1546
    },
    "colab_type": "code",
    "id": "qF3aVs-LGTWI",
    "outputId": "d8c44161-d9f6-41cf-8611-18daed3a60d2"
   },
   "outputs": [],
   "source": [
    "## lets have a look at the categories and their distribution in all the categorical columns.\n",
    "\n",
    "for i in cat_cols:\n",
    "    print('Column Name: ',i)\n",
    "    print(df[i].value_counts())\n",
    "    print('-----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('all variables:',df.keys())\n",
    "variables = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "       'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
    "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "       'PaymentMethod', 'MonthlyCharges', 'TotalCharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.get_dummies(df[variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "X = pd.get_dummies(df_processed,drop_first=False)\n",
    "y = df['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(     \n",
    "                            X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=2,criterion='entropy',min_samples_leaf=25)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict_proba(X_test)[:,1]\n",
    "y_train_pred = clf.predict_proba(X_train)[:,1]\n",
    "print ('train,test roc:',metrics.roc_auc_score(y_train,y_train_pred),metrics.roc_auc_score(y_test,y_test_pred))\n",
    "fpr, tpr, thresholds  = metrics.roc_curve(y_train,y_train_pred)\n",
    "plt.plot([0,1],[0,1],'r--',label='Chance')\n",
    "plt.plot(fpr,tpr,'b',label='Train results')\n",
    "fpr, tpr, thresholds  = metrics.roc_curve(y_test,y_test_pred)\n",
    "plt.plot(fpr,tpr,'g',label='Test results')\n",
    "\n",
    "plt.xlabel('True positive rate')\n",
    "plt.ylabel('False positive rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz \n",
    "import pydot\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                                feature_names=X.keys(),  \n",
    "                      class_names=\"Survived\",  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph.render(\"Churn\",format='png') \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(20,20))\n",
    "plt.imshow(plt.imread('./Explain.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a more complicated model\n",
    "clf = tree.DecisionTreeClassifier(max_depth=4,criterion='entropy',min_samples_leaf=25)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict_proba(X_test)[:,1]\n",
    "y_train_pred = clf.predict_proba(X_train)[:,1]\n",
    "print ('train,test roc:',metrics.roc_auc_score(y_train,y_train_pred),metrics.roc_auc_score(y_test,y_test_pred))\n",
    "fpr, tpr, thresholds  = metrics.roc_curve(y_train,y_train_pred)\n",
    "plt.plot([0,1],[0,1],'r--',label='Chance')\n",
    "plt.plot(fpr,tpr,'b',label='Train results')\n",
    "fpr, tpr, thresholds  = metrics.roc_curve(y_test,y_test_pred)\n",
    "plt.plot(fpr,tpr,'g',label='Test results')\n",
    "\n",
    "plt.xlabel('True positive rate')\n",
    "plt.ylabel('False positive rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz \n",
    "import pydot\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                                feature_names=X.keys(),  \n",
    "                      class_names=\"Survived\",  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph.render(\"Churn\",format='png') \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stradegies to reduce churn"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Survival_analysis.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "python3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
